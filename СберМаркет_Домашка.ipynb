{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4483ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb311388",
   "metadata": {},
   "source": [
    "# Задание\n",
    "https://docs.google.com/document/d/1ibPcLG5TZfi6OKgSjwcWRuLKpJHbpU57vmfsONBMNNE/edit#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186fce6a",
   "metadata": {},
   "source": [
    "**Комментарий к заданию:**<br>\n",
    "\"будет круто если сделаешь что-то оригинальное, например гео анализ и вывод на интерактивную карту, когортный анализ, твой вариант юнит экономики, ML, притянуть сторонние данные и поискать корреляции, сложные модели, модели из эконометрики, ARIMA, AR, GARCH, совместные распределения переменных и тд, посчитать ретеншн и тд\n",
    "- желательно посчитать какой-нибудь сложный запрос - например ретеншн, сложную группировку и тд в SQL\n",
    "- желательно посчитать seaborn, folium и тд, чтобы была красивая визуализация\n",
    "- по логике - хочется гипотез и so what по каждой, а еще круто структурировать все по разделам и сделать содержание или еще лучше презентацию, чтобы показать как ты сможешь презентовать свои проекты и идеи, которые будешь лидировать стейкхолдерам\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be9d024",
   "metadata": {},
   "source": [
    "### TODO и идеи\n",
    "**Гео-анализ:** карта распределения выручки / числа заказов. Libs - AltAir, Plotly, Folium.\n",
    "<br><br> **Кластеризация:** группировка клиентов по их поведению - сумма, частота заказа (\"домохозяйки\", \"рандомные вкусняшки\", \"корпораты\" итд)\n",
    "<br><br> **Временные ряды:** Libs - Facebook Prophet, ARIMA, AR, GARCH. \n",
    "<br><br> **Метрики + инженерия признаков:** \n",
    "1. GMV / GTV + средняя сумма заказа на человека / адрес / активного человека\n",
    "2. Average items per order \n",
    "3. Buyer-2-Delievery ratio - опоздания заказов\n",
    "4. Распределение выручки по магазинам / пользователям / городам\n",
    "5. Repeat Purchase Rate (RPR) / Purchase Frequency (PF)\n",
    "6. Aquisition cost per customer - скидка новым клиентам / число клиентов\n",
    "7. Доля адресов в регионе, которая делала заказ (то есть конверсия регистрации в заказы)\n",
    "8. Число магазинов на душу клиентской базы / наоборот (<- то есть сколько клиентов на один магазин приходится)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461990ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import psycopg2\n",
    "# from fbprophet import Prophet\n",
    "import plotly\n",
    "# import folium\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250c3aa",
   "metadata": {},
   "source": [
    "Подключимся к базе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6402aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очевидно, нужно иметь файл со строкой подключения в папке, чтобы это не сработало\n",
    "with open('pg_creds.cred', 'r') as f:\n",
    "    conn_str = f.read()\n",
    "\n",
    "pg_engine = sa.create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018ae5d",
   "metadata": {},
   "source": [
    "# Анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa3a06",
   "metadata": {},
   "source": [
    "### ГЕО \n",
    "Если мы хотим получить аналитику в разрезе регионов, нам необходимо провести кодировку адресов по полигонам областей РФ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd6e40",
   "metadata": {},
   "source": [
    "https://vc.ru/dev/242585-kak-sozdat-interaktivnuyu-kartu-cherez-folium\n",
    "<br>\n",
    "https://habr.com/ru/post/502958/\n",
    "<br>\n",
    "https://towardsdatascience.com/a-complete-guide-to-an-interactive-geographical-map-using-python-f4c5197e23e0\n",
    "<br>\n",
    "https://habr.com/ru/company/ods/blog/338554/\n",
    "<br>\n",
    "https://towardsdatascience.com/choropleth-maps-with-folium-1a5b8bcdd392\n",
    "<br>\n",
    "https://stackoverflow.com/questions/55563700/choropleth-map-is-not-showing-color-variation-in-the-output\n",
    "<br>\n",
    "https://stackoverflow.com/questions/61415557/folium-choropleth-issue\n",
    "<br>\n",
    "http://python-visualization.github.io/folium/quickstart.html#GeoJSON/TopoJSON-Overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Адреса в базе\n",
    "\n",
    "addresses = pd.read_sql(sql=\"select * from addresses\", con=pg_engine)\n",
    "\n",
    "# Файл с полигонами РФ\n",
    "\n",
    "polys = gpd.read_file('RF_regions.geojson')\n",
    "polys['id'] = polys.index\n",
    "\n",
    "\n",
    "polys = polys[['name', 'ref', 'id', 'geometry']]\n",
    "# Удалим регионы, которые явно не из РФ + дубликаты\n",
    "polys = polys[~polys['name'].isin(['Сумска', \"Автономна Республіка Крим\"])]\n",
    "polys.drop_duplicates(subset=['name'], inplace=True) \n",
    "# Закодируем Крым и Севастополь\n",
    "polys.loc[polys['name'] == 'Республика Крым', 'ref'] = 'CRY'\n",
    "polys.loc[polys['name'] == 'Севастополь', 'ref'] = 'SEV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Два разных файла, так как по-началу были проблемы с одним из форматов\n",
    "polys[['id', 'geometry']].to_file('RF_regions_id_geometry.geojson', driver='GeoJSON')\n",
    "# polys[['id', 'geometry']].to_file('RF_regions_id_geometry.json', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799aeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь к каждому адресу нужно подогнать region name\n",
    "\n",
    "geo_addresses = gpd.GeoDataFrame(addresses, geometry=gpd.points_from_xy(x=addresses['lon'], y=addresses['lat']))\n",
    "\n",
    "# Для каждого адреса притянем его регион\n",
    "\n",
    "geo_addresses = gpd.sjoin(geo_addresses, polys, how='left', op=\"within\")\n",
    "\n",
    "# Приведем в человеческий вид датафрейм\n",
    "geo_addresses.rename(mapper={\"id_left\": 'address_id', 'id_right': 'region_id'}, axis=1, inplace=True)\n",
    "geo_addresses.drop(columns=['lat', 'lon', 'index_right'], axis=1, inplace=True)\n",
    "\n",
    "# Справочник регионов для притягивания названий к датафреймам\n",
    "regions = geo_addresses[['name', 'region_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем тестовую группировку - число адресов по регионам\n",
    "\n",
    "adds_cnt_per_region = pd.DataFrame(geo_addresses.groupby(by=['ref', 'name', 'region_id'])['address_id'].count()).reset_index()\n",
    "adds_cnt_per_region.rename(mapper={'address_id': 'cnt_addresses'}, axis=1, inplace=True)\n",
    "# adds_cnt_per_region.rename(mapper={'region_id': 'id'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(adds_cnt_per_region.info())\n",
    "\n",
    "adds_cnt_per_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[55.75, 36.72], zoom_start=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ade0fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rel_ = folium.Choropleth(\n",
    "#     geo_data = polys[['ref', 'geometry']].to_json(), \n",
    "    geo_data = 'RF_regions_id_geometry.geojson', \n",
    "    name = 'Пользователи СберМаркета по регионам',\n",
    "    data = adds_cnt_per_region,\n",
    "    columns=['region_id', 'cnt_addresses'], \n",
    "    key_on=\"feature.properties.id\",\n",
    "    fill_color=\"BuPu\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name= 'Пользователи СберМаркета по регионам', \n",
    "    nan_fill_color='black'\n",
    ")\n",
    "\n",
    "rel_.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данная карта имеет 0 бизнес-смысла (ну разве что о крайне неравномерном распределении числа пользователей по регионам РФ. Но это не новая инфа). Карта нужна исключительно для теста.\n",
    "# Черным, кстати, отмечены те регионы, в которых зарегано 0 адресов\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2347f",
   "metadata": {},
   "source": [
    "#### Убедившись, что все работает, перейдем к исследованию данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc173a62",
   "metadata": {},
   "source": [
    "# Из всех запросов убираем 18 декабря, так как там явно неполные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae41ff",
   "metadata": {},
   "source": [
    "### GMV / GTV / Заказы\n",
    "\n",
    "**GMV** покажет нам, как много вообще товаров проходит через наш сервис, как активно заказывают покупатели. GMV не указывает на прибыльность сервиса, но является отличным индикативом того, насколько популярен сервис.\n",
    "<br><br>А вот **GTV** покажет именно выручку сервиса, то есть финансовые потоки именно в сам СберМаркет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Общий временной ряд GMV / GTV\n",
    "\n",
    "gmv_gtv_time_series_query = \"\"\"\n",
    "select\n",
    "    cast(o.\"created_at\" as date) as statsDate, sum(o.\"item_total\" + o.\"promo_total\") as net_GMV, sum(o.\"total_cost\") as net_GTV, count(*) as cnt_orders, avg(o.\"item_total\" + o.\"promo_total\") as avg_order_value\n",
    "from orders o\n",
    "where 1=1\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date)\n",
    "order by cast(o.\"created_at\" as date) desc\n",
    "\"\"\"\n",
    "\n",
    "gmv_gtv_ts = pd.read_sql(sql=gmv_gtv_time_series_query, \n",
    "                         con=pg_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 13), nrows=3, ncols=1)\n",
    "\n",
    "ax[0].plot(gmv_gtv_ts['statsdate'], gmv_gtv_ts['net_gmv'])\n",
    "ax[0].set(title='Net GMV time series')\n",
    "ax[0].set(xlabel='Дата')\n",
    "ax[0].set(ylabel='Десятки млн рублей')\n",
    "\n",
    "ax[1].plot(gmv_gtv_ts['statsdate'], gmv_gtv_ts['net_gtv'])\n",
    "ax[1].set(title='Net GTV time series')\n",
    "ax[1].set(xlabel='Дата')\n",
    "ax[1].set(ylabel='Миллионы рублей')\n",
    "\n",
    "ax[2].plot(gmv_gtv_ts['statsdate'], gmv_gtv_ts['cnt_orders'])\n",
    "ax[2].set(title='# of orders time series')\n",
    "ax[2].set(xlabel='Дата')\n",
    "ax[2].set(ylabel='Число заказов')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('GMV_GTV_cnt_orders.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5aeb2e",
   "metadata": {},
   "source": [
    "Посмотрим, а как же распределено число заказов по регионам. Что являлось, например, причиной просадки в районе августа 2019? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea59b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_orders_cnt_query = \"\"\"\n",
    "select\n",
    "    cast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id, count(*) as cnt_orders\n",
    "from orders o\n",
    "join spec_feature sf\n",
    "    on o.ship_address_id = sf.address_id\n",
    "group by cast(o.\"created_at\" as date), sf.my_feature_id\n",
    "order by cast(o.\"created_at\" as date)\n",
    "\"\"\"\n",
    "\n",
    "regional_orders_cnt = pd.read_sql(sql=regional_orders_cnt_query, con=pg_engine)\n",
    "regional_orders_cnt = regional_orders_cnt.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число заказов по регионам, Мск\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=regional_orders_cnt[regional_orders_cnt['name'] == 'Москва'], x='statsdate', y='cnt_orders', hue='name');\n",
    "\n",
    "# Без Мск\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=regional_orders_cnt[regional_orders_cnt['name'] != 'Москва'], x='statsdate', y='cnt_orders', hue='name');\n",
    "\n",
    "# Без Мск и Рост области\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=regional_orders_cnt[(regional_orders_cnt['name'] != 'Москва') & (regional_orders_cnt['name'] != 'Ростовская область')], x='statsdate', y='cnt_orders', hue='name');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Без Мск\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=regional_orders_cnt[regional_orders_cnt['name'] != 'Москва'], x='statsdate', y='cnt_orders', hue='name')\n",
    "ax.set(xlabel='Дата', ylabel='Число заказов', title='Общая динамика')\n",
    "plt.savefig('General dynamics.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e085245",
   "metadata": {},
   "source": [
    "Просадка по числу заказов происходит во всех регионах, тренд по сути везде копируется, разница разве что в степени.<br>\n",
    "Раз это не связано с географией, то, как мне кажется, это может быть поломка мобильного приложения? Это будет правдой, если снижение числа заказов является однодневным (ну пару-тройку дней максимум).<br>\n",
    "Проверим это: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_days_inquiry_query = \"\"\"select \n",
    "        cast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id, count(*) as cnt_orders\n",
    "    from orders o\n",
    "    join spec_feature sf\n",
    "        on o.\"ship_address_id\" = sf.address_id\n",
    "    where 1=1\n",
    "        and o.\"created_at\" >= '2019-07-30'::date\n",
    "        and o.\"created_at\" < '2019-08-30'::date\n",
    "    group by cast(o.\"created_at\" as date), sf.my_feature_id\n",
    "    order by cast(o.\"created_at\" as date)\n",
    "    \"\"\"\n",
    "low_days = pd.read_sql(sql=low_days_inquiry_query, con=pg_engine)\n",
    "low_days = low_days.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407bc0ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# График дней с аномальной просадкой\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=low_days, x='statsdate', y='cnt_orders', ci=None, hue='name')\n",
    "ax.set(ylabel=\"Число заказов\", xlabel='Дата', title=\"Просадка числа заказов в августе'19\")\n",
    "plt.savefig('low_days_august_2019.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55963b",
   "metadata": {},
   "source": [
    "Число заказов просело драматически. Я уверен наверняка, что это никак не связано со спросом. Единственный вариант - просадка со стороны предложения.<br>\n",
    "Даунтайм приложения на пару дней? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09383ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(gmv_gtv_ts['statsdate'], gmv_gtv_ts['avg_order_value'])\n",
    "ax.set(title='Средняя сумма заказа')\n",
    "ax.set(xlabel='Дата')\n",
    "ax.set(ylabel='Рубли')\n",
    "plt.savefig('Avg_cart_value.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc82c756",
   "metadata": {},
   "source": [
    "**Что видно:**\n",
    "- Большие изменения ГМВ в первую очередь связаны с изменением числа заказов - не со средней суммой заказа. То есть можно сказать, что именно число заказов определяет главные финансовые потоки.\n",
    "- Средняя сумма заказа выглядит как некий случайный процесс, без особого тренда. Процесс выглядит +- статичным, хотя \"стабильность\" явно нарушается после июля 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf53c8",
   "metadata": {},
   "source": [
    "**Что дальше:**<br>\n",
    "Просто временной ряд GMV мало, что нам скажет. Посмотрим на региональное распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f595dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_addresses['address_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим, как менялась доля различных регионов в GMV, GTV и число заказов\n",
    "# Для этого сначала зальем в базу айдишки регионов\n",
    "data_is_in_DB = True\n",
    "\n",
    "if not data_is_in_DB:  # Флаг, чтобы можно было просто щелкать на прогон ячейки и не бояться, что снова все запишется в базу\n",
    "\n",
    "    data_for_sql = geo_addresses[['address_id', 'region_id']].drop_duplicates()\n",
    "    data_for_sql.rename(mapper={'region_id': 'my_feature_id'}, axis=1, inplace=True)\n",
    "    # data_for_sql.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    pg_engine_for_batch_insert = sa.create_engine(\"postgresql+psycopg2://analytics:HRanalytics@rc1c-fhrb9f1e0l9g611h.mdb.yandexcloud.net:6432/hr-analytics?sslmode=require\", use_batch_mode=True)\n",
    "\n",
    "    chunk_size = 50000\n",
    "\n",
    "    chunk_num = 1\n",
    "\n",
    "    print('Started: ', datetime.now())\n",
    "\n",
    "    while True:\n",
    "\n",
    "        print((chunk_num - 1) * chunk_size, chunk_num * chunk_size)  # Какой срез от датафрейма берем\n",
    "\n",
    "        if chunk_num * chunk_size > data_for_sql.shape[0]:\n",
    "\n",
    "            print(f'Writing the last chunk number {chunk_num}', datetime.now())\n",
    "            data_for_sql[(chunk_num - 1) * chunk_size:].to_sql(name='spec_feature', \n",
    "                                                               con=pg_engine_for_batch_insert, schema='public', if_exists='append', index=False)\n",
    "            print(f'Done writing the last chunk chunck number {chunk_num}', datetime.now())\n",
    "        else:\n",
    "            print(f'Writing chunck number {chunk_num}', datetime.now())\n",
    "            data_for_sql[(chunk_num - 1) * chunk_size:chunk_num * chunk_size].to_sql(name='spec_feature', \n",
    "                                                                                       con=pg_engine_for_batch_insert, schema='public', \n",
    "                                                                                       if_exists='append', index=False)\n",
    "            print(f'Done writing chunck number {chunk_num}', datetime.now())\n",
    "\n",
    "        chunk_num += 1\n",
    "        print('\\n\\n')\n",
    "\n",
    "        if chunk_size * (chunk_num - 1) > data_for_sql.shape[0]:  # Выходим, когда все записали \n",
    "            break\n",
    "\n",
    "    pg_engine_for_batch_insert.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7987056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя сумма заказа\n",
    "\n",
    "avg_order_value_query = \"\"\"\n",
    "select\n",
    "\tcast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id\n",
    "\t, avg(o.\"item_total\" + o.\"promo_total\") as avg_order_value\n",
    "from orders o \n",
    "join spec_feature sf \n",
    "\ton o.ship_address_id = sf.address_id \n",
    "where 1=1\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date), sf.my_feature_id \n",
    "order by cast(o.\"created_at\" as date)\n",
    "\"\"\"\n",
    "\n",
    "avg_order_value = pd.read_sql(sql=avg_order_value_query, con=pg_engine)\n",
    "avg_order_value = avg_order_value.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_order_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя сумма заказа по регионам\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=avg_order_value, x='statsdate', y='avg_order_value', hue='name');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff0c45",
   "metadata": {},
   "source": [
    "Интересно, что Москва не является лидером по средней сумме заказа.<br>\n",
    "Москва стабильно находится в диапазоне 4-6 тысяч рублей на заказ, тогда как, например, Нижегородская область порой имеет сумму заказов до 14 тысяч рублей.<br>\n",
    "*Возможно*, это связано связано с тем, что там существуют корпоративные закупки и они составляют значимую долю заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя скидка на заказ\n",
    "\n",
    "avg_disc_query = \"\"\"\n",
    "select\n",
    "\tcast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id\n",
    "\t, - 100.0 * avg(o.\"promo_total\" / o.\"item_total\") as avg_discount\n",
    "from orders o \n",
    "join spec_feature sf \n",
    "\ton o.ship_address_id = sf.address_id \n",
    "where 1=1\n",
    "    and o.\"item_total\" > 0\n",
    "    and o.\"item_total\" + o.\"promo_total\" >= 0\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date), sf.my_feature_id \n",
    "order by cast(o.\"created_at\" as date)\n",
    "\"\"\"\n",
    "\n",
    "avg_disc = pd.read_sql(sql=avg_disc_query, con=pg_engine)\n",
    "avg_disc = avg_disc.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe47cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя скидка на заказ\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=avg_disc, x='statsdate', y='avg_discount', hue='name');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вот теперь посчитаем долю регионов в GMV, GTV и числе заказов в динамике\n",
    "\n",
    "regions_share_query = \"\"\"\n",
    "with orders_data as \n",
    "(\n",
    "\tselect\n",
    "\t\to.ship_address_id \n",
    "\t\t, o.\"item_total\" + o.\"promo_total\" as net_gmv\n",
    "\t\t, o.\"total_cost\" as net_gtv\n",
    "\t\t, count(*) over (partition by cast(o.\"created_at\" as date)) as cnt_orders_total\n",
    "\t\t, sum(o.\"item_total\" + o.\"promo_total\") over (partition by cast(o.\"created_at\" as date)) as net_gmv_total\n",
    "\t\t, sum(o.\"total_cost\") over (partition by cast(o.\"created_at\" as date)) as net_gtv_total\n",
    "\t\t, cast(o.\"created_at\" as date) as statsDate\n",
    "\tfrom orders o \n",
    "\twhere 1=1\n",
    "        and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    ")\n",
    "\n",
    "select\n",
    "\tod.statsdate\n",
    "\t, sf.my_feature_id\n",
    "\t, 100.0 * sum(od.\"net_gmv\") / max(od.\"net_gmv_total\") as share_in_gmv\n",
    "\t, 100.0 * sum(od.\"net_gtv\") / max(od.\"net_gtv_total\") as share_in_gtv\n",
    "\t, 100.0 * count(*) / max(od.cnt_orders_total) as share_in_orders\n",
    "from orders_data as od\n",
    "join spec_feature sf \n",
    "\ton od.ship_address_id = sf.address_id \n",
    "where 1=1\n",
    "group by od.statsdate, sf.my_feature_id \n",
    "order by od.statsdate desc\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "regions_share = pd.read_sql(sql=regions_share_query, con=pg_engine)\n",
    "regions_share = regions_share.merge(regions, left_on='my_feature_id', right_on='region_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доли регионов в GMV\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=regions_share, x='statsdate', y='share_in_gmv', hue='name')\n",
    "ax.set(xlabel='Дата', ylabel='%', title='Доля регионов в GMV')\n",
    "plt.savefig('Regions_share_in_GMV.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa78c8",
   "metadata": {},
   "source": [
    "Из-за слишком высокой доли Москвы в GMV, график не слишком информативен для других регионов.<br>\n",
    "**Но!** Доля Москвы достаточно последовательно, плавно, но снижается. С доли примерно в 95% до порядка 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График без Москвы\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 9))\n",
    "sns.lineplot(data=regions_share[(regions_share['region_id'] != 64)], x='statsdate', y='share_in_gmv', hue='name');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a988b",
   "metadata": {},
   "source": [
    "То есть выходит, что лидер после Москвы - Ростовская область. Однако по графику кажется, что ближе к концу периода она от средней доли в 10 процентов уходит вниз до примерно 8, к Самарской и Московской областям.<br>\n",
    "Однако неясно, является ли причиной падения доли, общий рост GMV Мск и Сам. областей, или же падение Ростовской области по GMV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93352336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доли регионов в GTV\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=regions_share, x='statsdate', y='share_in_gtv', hue='name');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e3776",
   "metadata": {},
   "source": [
    "Опять же, зависимость компании от Московского рынка снижается - и это хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac29afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График без Москвы\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 9))\n",
    "sns.lineplot(data=regions_share[(regions_share['region_id'] != 64)], x='statsdate', y='share_in_gtv', hue='name');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96ff34",
   "metadata": {},
   "source": [
    "Ага, а вот тут уже интересно!<br>\n",
    "Примерно в июне 2019 получилось так, что дола Ростовской области в GTV сильно выросла. Хотя при этом с GMV такого не происходило. <br>\n",
    "Есть ощущение, что рост доли Ростовской области происходит в основном из-за падения доли Москвы. <br>\n",
    "То есть возможно, что в Москве (и других регионах) включились скидки на доставку. <br>\n",
    "**Проверим**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1240d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "delievery_disc_query = \"\"\"\n",
    "    with orders_data as \n",
    "    (\n",
    "        select\n",
    "            o.\"ship_address_id\"\n",
    "            , case \n",
    "                when o.\"cost\" > 0 \n",
    "                    then (o.\"cost\" - o.\"total_cost\") / o.\"cost\" \n",
    "                else null\n",
    "            end as delievery_discount\n",
    "            , cast(o.\"created_at\" as date) as statsDate\n",
    "        from orders o \n",
    "        where 1=1\n",
    "            and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "    )\n",
    "\n",
    "    select\n",
    "        od.statsdate\n",
    "        , sf.my_feature_id\n",
    "        , avg(od.\"delievery_discount\") * 100 as avg_delievery_discount\n",
    "    from orders_data as od\n",
    "    join spec_feature sf \n",
    "        on od.ship_address_id = sf.address_id \n",
    "    where 1=1\n",
    "    group by od.statsdate, sf.my_feature_id \n",
    "    order by od.statsdate desc\n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "deliev_disc = pd.read_sql(sql=delievery_disc_query, con=pg_engine)\n",
    "deliev_disc = deliev_disc.merge(regions, left_on='my_feature_id', right_on='region_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скидка на доставку по регионам\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.lineplot(data=deliev_disc, x='statsdate', y='avg_delievery_discount', hue='name');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8d53f",
   "metadata": {},
   "source": [
    "##### Среднее число продуктов в корзине"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_items_per_order_query = \"\"\"\n",
    "select \n",
    "\tcast(o.created_at as date) as statsDate, sf.my_feature_id as region_id\n",
    "\t, avg(o.\"total_weight\") / 1000 as mean_order_weight\n",
    "\t, avg(o.\"total_quantity\") as mean_items_per_order\n",
    "\t, avg(o.\"total_weight\" / (1000 * o.\"total_quantity\")) as mean_weight_per_item\n",
    "from orders o \n",
    "join spec_feature sf\n",
    "\ton o.ship_address_id = sf.address_id\n",
    "where 1=1\n",
    "\tand o.\"total_quantity\" > 0\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.created_at as date), sf.my_feature_id\n",
    "order by cast(o.created_at as date)\n",
    "\"\"\"\n",
    "\n",
    "items_per_order = pd.read_sql(sql=avg_items_per_order_query, con=pg_engine)\n",
    "items_per_order = items_per_order.merge(regions, left_on='region_id', right_on='region_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da49b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее число позиций в заказе по регионам\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=items_per_order, x='statsdate', y='mean_items_per_order', hue='name');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний вес товара в корзине\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=items_per_order, x='statsdate', y='mean_weight_per_item', hue='name', );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdad0fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Средний вес заказа\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=items_per_order, x='statsdate', y='mean_order_weight', hue='name', );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd1342",
   "metadata": {},
   "source": [
    "#### Доля заказов, которая опоздала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f6f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateness_rate_query = \"\"\"\n",
    "select\n",
    "\tcast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id\n",
    "\t, 100.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at >= '00:25:00'::interval\n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as lateness_rate\n",
    "from orders o\n",
    "join delivery_windows dw \n",
    "\ton o.delivery_window_id = dw.id \n",
    "join spec_feature sf \n",
    "\ton o.ship_address_id = sf.address_id \n",
    "where 1=1\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date), sf.my_feature_id \n",
    "order by cast(o.\"created_at\" as date)\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "lateness_rate = pd.read_sql(sql=lateness_rate_query, con=pg_engine)\n",
    "lateness_rate = lateness_rate.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd97d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateness_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f56584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доля опозданий в заказах по регионам\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=lateness_rate, x='statsdate', y='lateness_rate', hue='name')\n",
    "ax.set(xlabel='Дата', ylabel='%', title='Доля опоздавших заказов в разрезе по регионам')\n",
    "plt.savefig('Lateness_rate_regionwise.png', dpi=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d4553",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# В целом опоздавшие заказы\n",
    "\n",
    "total_lateness_rate_query = \"\"\"\n",
    "select\n",
    "\tcast(o.\"created_at\" as date) as statsdate\n",
    "\t, 1.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at >= '00:25:00'::interval\n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as lateness_rate\n",
    "from orders o\n",
    "join delivery_windows dw \n",
    "\ton o.delivery_window_id = dw.id\n",
    "where 1=1\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date)\n",
    "order by cast(o.\"created_at\" as date)\n",
    "\"\"\"\n",
    "\n",
    "total_lateness_rate = pd.read_sql(sql=total_lateness_rate_query, con=pg_engine)\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=lateness_rate, x='statsdate', y='lateness_rate', ci=None)\n",
    "ax.set(xlabel='Дата', ylabel='%', title='Доля опоздавших заказов')\n",
    "plt.savefig('Lateness_rate.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40841d",
   "metadata": {},
   "source": [
    "**То есть:**<br>\n",
    "В целом, доля опозданий находится в пределах 40 процентов, но \"на местах\" (конкретных регионах) могут быть дни с долей опоздавших заказов в **60-80% (!!)**<br>\n",
    "**Однако!** Важен не просто факт опоздания, а время, на которое опоздал курьер. Скорее всего 10-20 минут - несущественное опоздание.<br>\n",
    "Посмотрим в разрезе серьезности опоздания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ec521",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateness_severness_query = \"\"\"\n",
    "    select\n",
    "        cast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id\n",
    "        , 100.0 * sum(case \n",
    "            when o.shipped_at - dw.ends_at > '00:00:00'::interval and o.shipped_at - dw.ends_at <= '00:15:00'::interval \n",
    "                then 1\n",
    "            else 0 end) / count(*) as under_15_min\n",
    "        , 100.0 * sum(case \n",
    "            when o.shipped_at - dw.ends_at > '00:15:00'::interval and o.shipped_at - dw.ends_at <= '00:30:00'::interval \n",
    "                then 1\n",
    "            else 0 end) / count(*) as under_30_min\n",
    "        , 100.0 * sum(case \n",
    "            when o.shipped_at - dw.ends_at > '00:30:00'::interval and o.shipped_at - dw.ends_at <= '01:00:00'::interval \n",
    "                then 1\n",
    "            else 0 end) / count(*) as under_60_min\n",
    "        , 100.0 * sum(case \n",
    "            when o.shipped_at - dw.ends_at > '01:00:00'::interval and o.shipped_at - dw.ends_at <= '03:00:00'::interval \n",
    "                then 1\n",
    "            else 0 end) / count(*) as under_3_hour\n",
    "        , 100.0 * sum(case \n",
    "            when o.shipped_at - dw.ends_at > '03:00:00'::interval --and o.shipped_at - dw.ends_at <= '03:00:00'::interval \n",
    "                then 1\n",
    "            else 0 end) / count(*) as more_3_hour\n",
    "    from orders o\n",
    "    join delivery_windows dw \n",
    "        on o.delivery_window_id = dw.id \n",
    "    join spec_feature sf \n",
    "        on o.ship_address_id = sf.address_id \n",
    "    where 1=1\n",
    "        and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "    group by cast(o.\"created_at\" as date), sf.my_feature_id \n",
    "    order by cast(o.\"created_at\" as date)\n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "lateness_severeness = pd.read_sql(sql=lateness_severness_query, con=pg_engine)\n",
    "lateness_severeness = lateness_severeness.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateness_severeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d48d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=lateness_severeness, x='statsdate', y='more_3_hour', hue='name')\n",
    "ax.set(xlabel='Дата', ylabel='%', title='Доля заказов, опоздавших > 3 часа')\n",
    "plt.savefig('More_3_hour_lateness_rate.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaddb84",
   "metadata": {},
   "source": [
    "**Что видно:**<br>\n",
    "Период с большим число опозданий в Омской области содержал в себе именно самые критичные опоздания - более, чем на 3 часа. Можно сделать вывод, что одна из самых проблемных областей по логистике - Омская. Интересно , однако, что в дальнейшем ситуация улучшилась.<br>\n",
    "И в целом по всем регионам доля опозданий на более, чем 3 часа, упала."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433883d2",
   "metadata": {},
   "source": [
    "Посмотрим на одном графике все случаи: заказ доставлен или с опозданием (и каким) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b06727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нам нужен запрос, который вернет доли: без опозданий, 15 мин, 30 мин, 60 мин, 3 часа, > 3 часов\n",
    "\n",
    "lateness_stack_plot_query = \"\"\"\n",
    "select\n",
    "\tcast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id\n",
    "\t, 100.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at <= '00:00:00'::interval\n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as on_time\n",
    "\t, 100.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at > '00:00:00'::interval and o.shipped_at - dw.ends_at <= '00:15:00'::interval \n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as under_15_min\n",
    "\t, 100.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at > '00:15:00'::interval and o.shipped_at - dw.ends_at <= '00:30:00'::interval \n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as under_30_min\n",
    "\t, 100.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at > '00:30:00'::interval and o.shipped_at - dw.ends_at <= '01:00:00'::interval \n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as under_60_min\n",
    "\t, 100.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at > '01:00:00'::interval and o.shipped_at - dw.ends_at <= '03:00:00'::interval \n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as under_3_hour\n",
    "\t, 100.0 * sum(case \n",
    "\t\twhen o.shipped_at - dw.ends_at > '03:00:00'::interval --and o.shipped_at - dw.ends_at <= '03:00:00'::interval \n",
    "\t\t\tthen 1\n",
    "\t\telse 0 end) / count(*) as more_3_hour\n",
    "from orders o\n",
    "join delivery_windows dw \n",
    "\ton o.delivery_window_id = dw.id \n",
    "join spec_feature sf \n",
    "\ton o.ship_address_id = sf.address_id \n",
    "where 1=1\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date), sf.my_feature_id \n",
    "order by cast(o.\"created_at\" as date)\n",
    ";\n",
    "\"\"\"\n",
    "lateness_stackplot = pd.read_sql(sql=lateness_stack_plot_query, con=pg_engine)\n",
    "lateness_stackplot = lateness_stackplot.merge(regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389ecfe",
   "metadata": {},
   "source": [
    "**Список \"областей\":**<br>\n",
    "Татарстан<br>\n",
    "Москва<br>\n",
    "Московская область<br>\n",
    "Нижегородская область<br>\n",
    "Ростовская область<br>\n",
    "Башкортостан<br>\n",
    "Самарская область<br>\n",
    "Омская область<br>\n",
    "Калужская область<br>\n",
    "Санкт-Петербург"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64703cff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "choice = 'Омская область'\n",
    "one_region = lateness_stackplot[lateness_stackplot['name'] == choice]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "ax.plot([],[],color='forestgreen', label='Вовремя', linewidth=3)\n",
    "ax.plot([],[],color='lime', label='Опоздание 15 мин', linewidth=3)\n",
    "ax.plot([],[],color='yellow', label='Опоздание 30 мин', linewidth=3)\n",
    "ax.plot([],[],color='orange', label='Опоздание в час', linewidth=3)\n",
    "ax.plot([],[],color='red', label='Опоздание в 3 часа', linewidth=3)\n",
    "ax.plot([],[],color='black', label='Опоздание > 3 часов', linewidth=3)\n",
    "\n",
    "ax.stackplot(one_region['statsdate'], one_region['on_time'], one_region['under_15_min'], one_region['under_30_min'], one_region['under_60_min'], \n",
    "             one_region['under_3_hour'], one_region['more_3_hour'], \n",
    "#              colors=['tab:green', 'tab:blue', 'yellow', 'tab:orange', 'tab:red', 'black']\n",
    "             colors=['forestgreen', 'lime', 'yellow', 'orange', 'red', 'black']\n",
    "            )\n",
    "\n",
    "ax.set(xlabel='Дата', \n",
    "      ylabel='%', \n",
    "      title=f'{choice}')\n",
    "ax.legend(title='Цвета', loc='lower right', frameon=True)\n",
    "plt.savefig(f'{choice}_stackplot_lateness.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04287a",
   "metadata": {},
   "source": [
    "**Итого:**<br> \n",
    "- Самая \"проблемная\" область - Омская. В ней выше всего доля опоздавших > 3 часа заказов. Со временем ситуация стабилизировалась, но в самом начале существования это была по-настоящему проблемная точка. Исследование причин такого числа опозданий помогло бы компании научиться более \"гладко\" выходить в новые города."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef775a66",
   "metadata": {},
   "source": [
    "Выявим самые проблемные магазины (сети) (из которых курьеры чаще опаздывают) и регионы, в которых это происходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d060710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала по ретейлерам. Будем считать лишь опоздания на 20+ минут\n",
    "\n",
    "lateness_per_retailer_query = \"\"\"\n",
    "select\n",
    "\tcast(o.\"created_at\" as date) as statsdate, s.retailer_id\n",
    "\t, 100.0 * sum(case \n",
    "\t\t\twhen o.shipped_at - dw.ends_at >= '00:30:00'::interval \n",
    "\t\t\t\tthen 1\n",
    "\t\t\telse 0 end) / count(*) as severe_lateness_rate\n",
    "from orders o\n",
    "join stores s\n",
    "\ton o.store_id = s.id\n",
    "join delivery_windows dw \n",
    "\ton o.delivery_window_id = dw.id\n",
    "where 1=1\n",
    "    and cast(o.\"created_at\" as date) < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date), s.retailer_id\n",
    "order by cast(o.\"created_at\" as date)\n",
    "\"\"\"\n",
    "\n",
    "lateness_per_retailer = pd.read_sql(sql=lateness_per_retailer_query, con=pg_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateness_per_retailer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17256272",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=lateness_per_retailer, x='statsdate', y='severe_lateness_rate', hue='retailer_id', palette='tab10');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c8a6ce",
   "metadata": {},
   "source": [
    "Видно, что, например, сеть номер 16, как и сеть номер 8, имели большие проблемы с доставкой в самом начале своей \"жизни\".<br>\n",
    "Ситуация стала гораздо лучше к концу периода.<br>\n",
    "Интересно, что сеть номер 1 почти всегда имела очень стабильную ситуацию с опозданиями и держалась на уровне +- 10%<br>\n",
    "**Однако!** Информация о сети в целом мало что говорит. Интересно было бы посмотреть на конкретные магазины, в которых средний уровень опозданий курьера составляет 50+ процентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8af157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем те магазины, которые за июль, август, сентябрь, октябрь, ноябрь и декабрь имеют долю опозданий > 20% \n",
    "\n",
    "worst_stores_query = \"\"\"\n",
    "with prep as (\n",
    "\tselect\n",
    "\t\tcast(o.\"created_at\" as date) as statsdate, s.id\n",
    "\t\t, 100.0 * sum(case \n",
    "\t\t\t\twhen o.shipped_at - dw.ends_at >= '00:30:00'::interval \n",
    "\t\t\t\t\tthen 1\n",
    "\t\t\t\telse 0 end) / count(*) as severe_lateness_rate\n",
    "\tfrom orders o\n",
    "\tjoin stores s\n",
    "\t\ton o.store_id = s.id\n",
    "\tjoin delivery_windows dw \n",
    "\t\ton o.delivery_window_id = dw.id\n",
    "\twhere 1=1\n",
    "\tgroup by cast(o.\"created_at\" as date), s.id\n",
    "), \n",
    "bad_stores as (\n",
    "\tselect \n",
    "\t\tp1.id as store_id\n",
    "\tfrom prep p1\n",
    "\twhere 1=1\n",
    "\t\tand p1.statsdate >= '2019-07-01'::date\n",
    "\tgroup by p1.id\n",
    "\thaving avg(severe_lateness_rate) > 20.0\n",
    ")\n",
    "\n",
    "select \n",
    "\t*\n",
    "from prep p\n",
    "join bad_stores bs\n",
    "\ton p.\"id\" = bs.\"store_id\"\n",
    "\"\"\"\n",
    "\n",
    "worst_stores = pd.read_sql(sql=worst_stores_query, con=pg_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05588570",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518a269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=worst_stores, x='statsdate', y='severe_lateness_rate', hue='store_id', palette='tab10');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7738d25",
   "metadata": {},
   "source": [
    "Визуально кажется, что есть связь - чем \"моложе\" магазин, тем выше там доля опозданий (или, как минимум, выше дисперсия этой доли).<br> \n",
    "Попробуем проверить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим полиномиальную регрессию доли опозданий от \"возраста\" магазина в днях\n",
    "\n",
    "dataset_query = \"\"\"with prep as (\n",
    "\tselect\n",
    "\t\tcast(o.\"created_at\" as date) as statsdate, s.id\n",
    "\t\t, 100.0 * sum(case \n",
    "\t\t\t\twhen o.shipped_at - dw.ends_at >= '00:30:00'::interval \n",
    "\t\t\t\t\tthen 1\n",
    "\t\t\t\telse 0 end) / count(*) as severe_lateness_rate\n",
    "\t\t, cast(o.\"created_at\" as date) - min(cast(o.\"created_at\" as date)) over (partition by s.\"id\") as store_age\n",
    "\tfrom orders o\n",
    "\tjoin stores s\n",
    "\t\ton o.store_id = s.id\n",
    "\tjoin delivery_windows dw \n",
    "\t\ton o.delivery_window_id = dw.id\n",
    "\twhere 1=1\n",
    "\tgroup by cast(o.\"created_at\" as date), s.id\n",
    ")\n",
    "\n",
    "select\n",
    "\t*\n",
    "from prep\n",
    ";\"\"\"\n",
    "\n",
    "dataset = pd.read_sql(sql=dataset_query, con=pg_engine)\n",
    "dataset = dataset[['severe_lateness_rate', 'store_age']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(dataset[:, 0], dataset[:, 1])\n",
    "\n",
    "# Корреляция низкая, с отрицательным знаком (как и ожидалось), НО! Почти наверняка она статистически незначима. \n",
    "# Хотя важно помнить, что корреляция определяет лишь линейную связь. Другие (степенные) связи она может и не уловить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6cdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, 1]\n",
    "y = dataset[:, 0]\n",
    "X = np.asmatrix(X).reshape((X.shape[0], 1))\n",
    "\n",
    "lr = LinearRegression()\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_tr = pf.fit_transform(X)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_tr = min_max_scaler.fit_transform(X_tr)  # Сделаем признаки безразмерными, чтобы судить об их вкладе по коэффициентам\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tr, y, test_size=.3, shuffle=True)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)\n",
    "print('RMSE = ', ((y_hat - y_test) ** 2).mean() ** .5)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097b5ac",
   "metadata": {},
   "source": [
    "Результаты, конечно, не супер, но следовало ожидать. \n",
    "<br>RMSE очень высокий - 12.72. При том, что среднее значение опозданий - 8 (процентов). Так что с точки зрения предсказательной силы модели мы в пролете<br>\n",
    "Оно ожидаемо, так как вряд ли такой сложный процесс, как опоздание, будет отлично описываться одним лишь признаком - \"возрастом\" магазина.<br>\n",
    "По коэффициентам как будто бы судить тоже нельзя, ведь они друг друга почти уравновешивают."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb687e",
   "metadata": {},
   "source": [
    "**Repeated Purchase Rate и Purchase Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPR полезен тем, что указывает на долю клиентов, которые совершают несколько раз\n",
    "# Я предлагаю взять окно в 7 дней (как мне кажется, оптимально для покупок в \"больших\" магазинах)\n",
    "\n",
    "RPR_query = \"\"\"\n",
    "-- Посчитаем Repeated Purchase Rate по окнам в неделю: (#клиентов, которые заказали > 1 раза) / #клиентов\n",
    "\n",
    "-- трехнедельные окна. Тут day - это начало периода [lower; upper)\n",
    "with three_weeks as (\n",
    "\tSELECT t.lower_boundary::date, (t.lower_boundary::date + '7 day'::interval)::date as upper_boundary, row_number() over () as period_id\n",
    "\tFROM generate_series(timestamp '2018-08-26'\n",
    "\t                     , timestamp '2019-12-17'\n",
    "\t                     , interval  '7 day') AS t(lower_boundary)\n",
    ")\n",
    ", client_wise_prep as (\n",
    "\tselect \n",
    "\t\ttw.\"lower_boundary\", o.\"user_id\", count(*)\n",
    "\tfrom orders o\n",
    "\tjoin three_weeks tw\n",
    "\t\ton o.\"created_at\" >= tw.\"lower_boundary\"\n",
    "\t\t\tand o.\"created_at\" < tw.\"upper_boundary\"\n",
    "\twhere 1=1\n",
    "        and o.\"created_at\" < '2019-12-18'::date\n",
    "\tgroup by tw.\"lower_boundary\", o.\"user_id\"\n",
    "\thaving count(*) > 0\n",
    ")\n",
    "\n",
    "select\n",
    "\tcw.lower_boundary\n",
    "\t, 100 * sum(case when cw.\"count\" > 1 then 1.0 else 0 end) / sum(1.0) as RPR\n",
    "from client_wise_prep cw\n",
    "where 1=1\n",
    "group by cw.lower_boundary\n",
    "order by cw.\"lower_boundary\" desc\n",
    "\"\"\"\n",
    "\n",
    "rpr_data = pd.read_sql(sql=RPR_query, con=pg_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd17aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rpr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=rpr_data[rpr_data['lower_boundary'] < date(2019, 12, 15)], x='lower_boundary', y='rpr', palette='tab10', ci=None)\n",
    "ax.set(xlabel='Дата', ylabel='%', title='Доля повторных покупок')\n",
    "plt.savefig('RPR.png', dpi=600);\n",
    "\n",
    "# RPR, хотя и имеет колебания, все равно устойчиво растет с 6% до 11-12%+. Это говорит о том, что закупка через сбермаркет становится \"рутиной\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09ca7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Разбиение по регионам\n",
    "\n",
    "# RPR полезен тем, что указывает на долю клиентов, которые совершают несколько раз\n",
    "# Я предлагаю взять окно в 7 дней (как мне кажется, оптимально для покупок в \"больших\" магазинах)\n",
    "\n",
    "RPR_query = \"\"\"\n",
    "-- Посчитаем Repeated Purchase Rate по окнам в неделю: (#клиентов, которые заказали > 1 раза) / #клиентов\n",
    "\n",
    "-- трехнедельные окна. Тут day - это начало периода [lower; upper)\n",
    "with three_weeks as (\n",
    "\tSELECT t.lower_boundary::date, (t.lower_boundary::date + '7 day'::interval)::date as upper_boundary, row_number() over () as period_id\n",
    "\tFROM generate_series(timestamp '2018-08-26'\n",
    "\t                     , timestamp '2019-12-17'\n",
    "\t                     , interval  '7 day') AS t(lower_boundary)\n",
    ")\n",
    ", client_wise_prep as (\n",
    "\tselect \n",
    "\t\ttw.\"lower_boundary\", o.\"user_id\", max(sf.\"my_feature_id\") as region_id, count(*)\n",
    "\tfrom orders o\n",
    "\tjoin three_weeks tw\n",
    "\t\ton o.\"created_at\" >= tw.\"lower_boundary\"\n",
    "\t\t\tand o.\"created_at\" < tw.\"upper_boundary\"\n",
    "    join spec_feature sf\n",
    "        on o.ship_address_id = sf.address_id\n",
    "\twhere 1=1\n",
    "        and o.\"created_at\" < '2019-12-18'::date\n",
    "\tgroup by tw.\"lower_boundary\", o.\"user_id\"\n",
    "\thaving count(*) > 0\n",
    ")\n",
    "\n",
    "select\n",
    "\tcw.lower_boundary, cw.region_id\n",
    "\t, 100 * sum(case when cw.\"count\" > 1 then 1.0 else 0 end) / sum(1.0) as RPR\n",
    "from client_wise_prep cw\n",
    "where 1=1\n",
    "group by cw.lower_boundary, cw.region_id\n",
    "order by cw.\"lower_boundary\" desc\n",
    "\"\"\"\n",
    "\n",
    "rpr_data = pd.read_sql(sql=RPR_query, con=pg_engine)\n",
    "rpr_data = rpr_data.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=rpr_data[rpr_data['lower_boundary'] < date(2019, 12, 15)], x='lower_boundary', y='rpr', hue='name')\n",
    "ax.set(xlabel='Дата', ylabel='%', title='RPR по регионам')\n",
    "plt.savefig('RPR_regionwise.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edecdd2",
   "metadata": {},
   "source": [
    "Интересно, что некоторые регионы имеют менее уверенный тренд на рост, чем другие<br>\n",
    "Например, Москва вовсе не является лидером по данному показателю. Ее \"уделывает\" Ростовская и Самарская области, Татарстан итд."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243e82e",
   "metadata": {},
   "source": [
    "**Среднее число заказов на клиента за период (PF):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ad0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_query = \"\"\"\n",
    "with three_weeks as (\n",
    "\tSELECT t.lower_boundary::date, (t.lower_boundary::date + '7 day'::interval)::date as upper_boundary, row_number() over () as period_id\n",
    "\tFROM generate_series(timestamp '2018-08-26'\n",
    "\t                     , timestamp '2019-12-18'\n",
    "\t                     , interval  '7 day') AS t(lower_boundary)\n",
    ")\n",
    "\n",
    "select \n",
    "\ttw.\"lower_boundary\", sf.\"my_feature_id\" as region_id, 1.0 * count(*) / count(distinct o.\"user_id\") as pf\n",
    "from orders o\n",
    "join three_weeks tw\n",
    "\ton o.\"created_at\" >= tw.\"lower_boundary\"\n",
    "\t\tand o.\"created_at\" < tw.\"upper_boundary\"\n",
    "join spec_feature sf \n",
    "\ton o.\"ship_address_id\" = sf.address_id \n",
    "where 1=1\n",
    "group by tw.\"lower_boundary\", sf.\"my_feature_id\"\n",
    "having count(*) > 0\n",
    "order by tw.\"lower_boundary\"\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "pf_data = pd.read_sql(sql=pf_query, con=pg_engine)\n",
    "pf_data = pf_data.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=pf_data[pf_data['lower_boundary'] < date(2019, 12, 15)], x='lower_boundary', y='pf', hue='name');\n",
    "\n",
    "# Возможно, коррелирует с промо-акциями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372dfaca",
   "metadata": {},
   "source": [
    "**Среднее время между заказами:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_for_avg_time_between_orders = \"\"\"\n",
    "-- Как часто делается заказ в среднем (с окнами в 1.5 месяца)\n",
    "with six_weeks as (\n",
    "\tSELECT t.lower_boundary::date, (t.lower_boundary::date + '42 day'::interval)::date as upper_boundary, row_number() over () as period_id\n",
    "\tFROM generate_series(timestamp '2018-08-26'\n",
    "\t                     , timestamp '2019-12-18'\n",
    "\t                     , interval  '42 day') AS t(lower_boundary)\n",
    ")\n",
    ", prep as (\n",
    "\tselect \n",
    "\t\to.*, row_number() over (partition by o.user_id, sw.\"period_id\" order by o.created_at asc) as rn, sw.*\n",
    "\tfrom orders o \n",
    "\tjoin six_weeks sw\n",
    "\t\ton o.\"created_at\" >= sw.\"lower_boundary\"\n",
    "\t\t\tand o.\"created_at\" < sw.\"upper_boundary\"\n",
    ")\n",
    "\n",
    "\n",
    "select\n",
    "\tsf.my_feature_id as region_id, t1.\"lower_boundary\" as statsdate\n",
    "\t, avg(date_part('day', t2.\"created_at\" - t1.\"created_at\")) as avg_time_between_orders\n",
    "from prep as t1\n",
    "left join prep as t2\n",
    "\ton t1.user_id = t2.user_id\n",
    "\t\tand t2.rn = t1.rn + 1\n",
    "\t\tand t1.\"period_id\" = t2.\"period_id\"\n",
    "join spec_feature sf \n",
    "\ton t1.\"ship_address_id\" = sf.\"address_id\"\n",
    "where 1=1\n",
    "group by sf.my_feature_id, t1.\"lower_boundary\"\n",
    "order by t1.\"lower_boundary\" asc\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "avg_time_between_orders = pd.read_sql(sql=query_for_avg_time_between_orders, con=pg_engine)\n",
    "avg_time_between_orders = avg_time_between_orders.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561aa38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_time_between_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=avg_time_between_orders[avg_time_between_orders['statsdate'] < date(2019, 10, 20)], x='statsdate', y='avg_time_between_orders', palette='tab10', hue='name');\n",
    "plt.savefig('Avg_timedelta_between_orders.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b0200",
   "metadata": {},
   "source": [
    "Интересно, что такая метрика, как среднее время между заками почти не меняется и стабильно держится в районе 9 дней.<br>\n",
    "Разумеется, бизнес интересно было бы снижать данную метрику.<br>\n",
    "Однако мы видим, что местами она даже растет. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40373c01",
   "metadata": {},
   "source": [
    "### Влияние опозданий / ненайденных товаров на уход клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37436559",
   "metadata": {},
   "source": [
    "Доля заказов с ненайденными товарами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_items_query = \"\"\"\n",
    "select \n",
    "\tcast(o.\"created_at\" as date) as statsdate, sf.my_feature_id as region_id\n",
    "\t, 100.0 * count(distinct (\n",
    "\t\t\t\t\t\tcase when r.order_id is not null or c.order_id is not null\n",
    "\t\t\t\t\t\t\tthen o.id \n",
    "\t\t\t\t\t\t\telse null \n",
    "\t\t\t\t\t\tend\n",
    "\t)) / count(distinct o.id) as not_found_rate\n",
    "from orders o\n",
    "left join replacements r \n",
    "\ton o.id = r.order_id \n",
    "left join cancellations c \n",
    "\ton o.id = c.order_id \n",
    "join spec_feature sf \n",
    "\ton o.ship_address_id = sf.address_id \n",
    "where 1=1\n",
    "    and o.\"created_at\" < '2019-12-18'::date\n",
    "group by cast(o.\"created_at\" as date), sf.my_feature_id \n",
    "order by cast(o.\"created_at\" as date) desc\"\"\"\n",
    "\n",
    "lost_items = pd.read_sql(sql=lost_items_query, con=pg_engine)\n",
    "lost_items = lost_items.merge(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.lineplot(data=lost_items, x='statsdate', y='not_found_rate', hue='name', palette='tab10')\n",
    "ax.set(xlabel='Дата', ylabel='%', title='Доля заказов, в которой был ненайден хотя бы один товар. ')\n",
    "plt.savefig('Notfound_items_rate.png', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7058de",
   "metadata": {},
   "source": [
    "Получается, что обыденная картина (для всех регионов) - какой-то из товаров не находится в 70%+ заказов.<br>\n",
    "В целом кажется, что если один товар не нашелся - это ок.<br>\n",
    "Интересно было бы посмотреть в разбивке по числу товаров, которое не нашлось. И кажется, что важен процент корзины. <br>\n",
    "Однако у нас недостаточно данных, чтобы посчитать, какая доля товаров не нашлась.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ccbd78",
   "metadata": {},
   "source": [
    "Кажется разумным предположить, что чем больше происходит инцидентов с ненайденными товарами / опозданиями, тем выше шанс ухода клиента от компании<br>\n",
    "Проверим эту гипотезу:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9513107",
   "metadata": {},
   "source": [
    "Будем считать, что клиент ушел в отток, если его последний заказ состоялся до 15 ноября 2019. *Почему?*<br>\n",
    "Наши данные обрываются на 17 декабря. Можно считать, что перерыв заказах в месяц - еще +- нормальная история."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_testing_query = \"\"\"with prep as (\n",
    "\tselect \n",
    "\t\to.*, row_number() over (partition by o.\"user_id\" order by o.\"created_at\" desc) as rn -- Просто притащим нумерацию заказа для клиента по порядку. rn = 1 <- это последний заказ\n",
    "\tfrom orders o \n",
    "\twhere 1=1\n",
    "\t\t--and o.\"created_at\" < '2019-11-15'::date\n",
    ")\n",
    "-- Для каждого клиента посчитаем, сколько случаев \"с плохим опытом\" у него было до 15 числа\n",
    ", client_wise_bad_exp as (\n",
    "\tselect \n",
    "\t\tprep.\"user_id\"\n",
    "\t\t, (100.0 * count(distinct (case \n",
    "\t\t\t\twhen c.\"order_id\" is not null or r.\"order_id\" is not null or prep.\"shipped_at\" - dw.\"ends_at\" >= '01:00:00'::interval\n",
    "                --when prep.\"shipped_at\" - dw.\"ends_at\" >= '00:45:00'::interval\n",
    "\t\t\t\tthen prep.id \n",
    "\t\t\t\telse null \n",
    "\t\t\t\tend)) / count(distinct prep.id))::int as bad_exp_share\n",
    "\tfrom prep\n",
    "\tjoin delivery_windows dw\n",
    "\t\ton prep.delivery_window_id = dw.id\n",
    "\tleft join cancellations c\n",
    "\t\ton prep.id = c.\"order_id\"\n",
    "\tleft join replacements r\n",
    "\t\ton prep.id = r.\"order_id\"\n",
    "\twhere 1=1\n",
    "\t\tand prep.\"created_at\" < '2019-11-15'::date\n",
    "\tgroup by prep.\"user_id\"\n",
    "), \n",
    "\n",
    "churn as (\n",
    "\tselect \n",
    "\t\tdistinct \"user_id\"\n",
    "\tfrom prep\n",
    "\twhere 1=1\n",
    "\t\tand rn = 1\n",
    "\t\tand \"created_at\" < '2019-11-15'::date\n",
    ")\n",
    "\n",
    "\n",
    "select \n",
    "        case \n",
    "            when cwbe.bad_exp_share < 10\n",
    "\t\t\t\tthen 0\n",
    "\t\t\twhen cwbe.bad_exp_share >= 10 and cwbe.bad_exp_share < 20\n",
    "\t\t\t\tthen 1\n",
    "\t\t\twhen cwbe.bad_exp_share >= 20 and cwbe.bad_exp_share < 35\n",
    "\t\t\t\tthen 2\n",
    "\t\t\twhen cwbe.bad_exp_share >= 35 and cwbe.bad_exp_share < 50\n",
    "\t\t\t\tthen 3\n",
    "\t\t\twhen cwbe.bad_exp_share >= 50 and cwbe.bad_exp_share < 65\n",
    "\t\t\t\tthen 4\n",
    "\t\t\twhen cwbe.bad_exp_share >= 65 and cwbe.bad_exp_share < 80\n",
    "\t\t\t\tthen 5\n",
    "\t\t\telse 6\n",
    "\t\tend as bad_exp_severeness\n",
    "\t, 100.0 * count(c.\"user_id\") / count(cwbe.\"user_id\") as churn_rate\n",
    "from client_wise_bad_exp cwbe\n",
    "left join churn c\n",
    "\ton cwbe.\"user_id\" = c.\"user_id\"\n",
    "where 1=1\n",
    "group by case \n",
    "\t\t\twhen cwbe.bad_exp_share < 10\n",
    "\t\t\t\tthen 0\n",
    "\t\t\twhen cwbe.bad_exp_share >= 10 and cwbe.bad_exp_share < 20\n",
    "\t\t\t\tthen 1\n",
    "\t\t\twhen cwbe.bad_exp_share >= 20 and cwbe.bad_exp_share < 35\n",
    "\t\t\t\tthen 2\n",
    "\t\t\twhen cwbe.bad_exp_share >= 35 and cwbe.bad_exp_share < 50\n",
    "\t\t\t\tthen 3\n",
    "\t\t\twhen cwbe.bad_exp_share >= 50 and cwbe.bad_exp_share < 65\n",
    "\t\t\t\tthen 4\n",
    "\t\t\twhen cwbe.bad_exp_share >= 65 and cwbe.bad_exp_share < 80\n",
    "\t\t\t\tthen 5\n",
    "\t\t\telse 6\n",
    "\t\tend\n",
    "order by case \n",
    "\t\t\twhen cwbe.bad_exp_share < 10\n",
    "\t\t\t\tthen 0\n",
    "\t\t\twhen cwbe.bad_exp_share >= 10 and cwbe.bad_exp_share < 20\n",
    "\t\t\t\tthen 1\n",
    "\t\t\twhen cwbe.bad_exp_share >= 20 and cwbe.bad_exp_share < 35\n",
    "\t\t\t\tthen 2\n",
    "\t\t\twhen cwbe.bad_exp_share >= 35 and cwbe.bad_exp_share < 50\n",
    "\t\t\t\tthen 3\n",
    "\t\t\twhen cwbe.bad_exp_share >= 50 and cwbe.bad_exp_share < 65\n",
    "\t\t\t\tthen 4\n",
    "\t\t\twhen cwbe.bad_exp_share >= 65 and cwbe.bad_exp_share < 80\n",
    "\t\t\t\tthen 5\n",
    "\t\t\telse 6\n",
    "\t\tend desc\"\"\"\n",
    "\n",
    "hyp_data = pd.read_sql(sql=hypothesis_testing_query, con=pg_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800dc01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571faa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.barplot(data=hyp_data, x='bad_exp_severeness', y='churn_rate')\n",
    "ax.set(xlabel='Степень плохого опыта', ylabel='Доля отточных клиентов', title='Отток как зависимость от плохого опыта')\n",
    "plt.savefig('Bad_exp_to_churn.png', dpi=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963b34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "135c128d",
   "metadata": {},
   "source": [
    "Здесь колонка bad_exp_severeness говорит о том, насколько плохой опыт получил клиент (чем больше цифра, тем в большей доле заказов у него были опоздания / замены / отмены).<br>\n",
    "А поле churn_rate говорит о доле клиентов, которые перестали пользоваться сервисом.<br>\n",
    "Данные получились довольно противоречивыми, так как среди тех, у кого плохой опыт составлял 10% заказов, в отток ушло аж 94 процента.<br>\n",
    "То есть какой-то монотонной связи не прослеживается. <br>\n",
    "Более того, самый низкий уровень оттока наблюдается у группы клиентов, которая в 65-80% заказов имела какие-то проблемы. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33b9e8",
   "metadata": {},
   "source": [
    "# TODO по машинному обучению:\n",
    "- FB Prophet - на макро уровне наверняка будет работать отвратно из-за разнородности данных (гипер роста в середине 2019)\n",
    "- Кластеризация (сгруппировать клиентов по типам и понять, есть ли разница их показателях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94c44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51dda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main_Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
